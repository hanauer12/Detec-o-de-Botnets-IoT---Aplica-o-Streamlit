"""
AplicaÃ§Ã£o Streamlit para DetecÃ§Ã£o de Botnets IoT
Utiliza o dataset N-BaIoT para treinar e avaliar modelos de classificaÃ§Ã£o
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import time
import os
from io import StringIO

from utils import (
    load_dataset, preprocess_data, train_random_forest,
    train_xgboost, train_model,
    evaluate_model, get_feature_importance, count_csv_files,
    find_suitable_target_columns, get_available_devices
)


def make_arrow_compatible(df):
    """
    Converte DataFrame para ser compatÃ­vel com PyArrow/Streamlit
    Converte tipos problemÃ¡ticos para strings ou tipos compatÃ­veis
    """
    df_copy = df.copy()
    
    # Converte tipos object que podem causar problemas
    for col in df_copy.columns:
        if df_copy[col].dtype == 'object':
            # Tenta converter para string se possÃ­vel
            try:
                df_copy[col] = df_copy[col].astype(str)
            except:
                pass
    
    return df_copy

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="DetecÃ§Ã£o de Botnets IoT",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS customizado para melhorar a aparÃªncia
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    </style>
""", unsafe_allow_html=True)

# Sidebar - NavegaÃ§Ã£o
st.sidebar.title("ğŸ“‹ NavegaÃ§Ã£o")
page = st.sidebar.radio(
    "Selecione uma pÃ¡gina:",
    ["ğŸ  Dashboard", "ğŸ“¤ Upload & PrÃ©-processamento", "ğŸ¤– Treinamento", "ğŸ“ˆ Resultados"]
)

# TÃ­tulo principal (sÃ³ mostra se nÃ£o for dashboard)
if page != "ğŸ  Dashboard":
    st.markdown('<h1 class="main-header">ğŸ›¡ï¸ N-BaIoT Intrusion Detection Lab</h1>', unsafe_allow_html=True)
    st.markdown("---")

# InicializaÃ§Ã£o de variÃ¡veis de sessÃ£o
if 'dataset_loaded' not in st.session_state:
    st.session_state.dataset_loaded = False
if 'data' not in st.session_state:
    st.session_state.data = None
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = False
if 'model' not in st.session_state:
    st.session_state.model = None
if 'results' not in st.session_state:
    st.session_state.results = None
if 'X_train' not in st.session_state:
    st.session_state.X_train = None
if 'X_test' not in st.session_state:
    st.session_state.X_test = None
if 'y_train' not in st.session_state:
    st.session_state.y_train = None
if 'y_test' not in st.session_state:
    st.session_state.y_test = None
if 'scaler' not in st.session_state:
    st.session_state.scaler = None
if 'label_encoder' not in st.session_state:
    st.session_state.label_encoder = None
if 'dataset_path' not in st.session_state:
    st.session_state.dataset_path = None
if 'auto_download_attempted' not in st.session_state:
    st.session_state.auto_download_attempted = False

# FunÃ§Ã£o para fazer download do dataset
def download_dataset():
    """Faz o download do dataset do Kaggle"""
    try:
        import kagglehub
        path = kagglehub.dataset_download("mkashifn/nbaiot-dataset")
        st.session_state.dataset_path = path
        return path, None
    except Exception as e:
        return None, str(e)

# Download automÃ¡tico do dataset na primeira execuÃ§Ã£o
# Mostra um banner no topo da pÃ¡gina se o dataset ainda nÃ£o foi baixado
if not st.session_state.dataset_path and not st.session_state.auto_download_attempted:
    st.session_state.auto_download_attempted = True
    
    # Container destacado para o download
    with st.container():
        st.markdown("---")
        st.markdown("### ğŸ”„ Download AutomÃ¡tico do Dataset")
        status_placeholder = st.empty()
        progress_placeholder = st.empty()
        
        status_placeholder.info("ğŸ”„ Iniciando download do dataset N-BaIoT do Kaggle... Isso pode levar alguns minutos na primeira vez.")
        
        progress_placeholder.progress(0, text="Conectando ao Kaggle...")
        path, error = download_dataset()
        
        if path:
            progress_placeholder.progress(100, text="Download concluÃ­do!")
            status_placeholder.success(f"âœ… **Dataset baixado com sucesso!**\n\nğŸ“ LocalizaÃ§Ã£o: `{path}`\n\nğŸ’¡ Agora vocÃª pode carregar os dados na pÃ¡gina 'ExploraÃ§Ã£o de Dados'")
            progress_placeholder.empty()
            time.sleep(1)
        else:
            progress_placeholder.empty()
            status_placeholder.error(f"âŒ **Erro ao baixar o dataset automaticamente**\n\nErro: `{error}`")
            st.warning("ğŸ’¡ **SoluÃ§Ãµes possÃ­veis:**")
            st.markdown("""
            - Certifique-se de que suas credenciais do Kaggle estÃ£o configuradas (veja `kaggle_setup.md`)
            - Verifique sua conexÃ£o com a internet
            - VocÃª pode tentar baixar manualmente na pÃ¡gina 'ExploraÃ§Ã£o de Dados'
            """)
        
        st.markdown("---")

# PÃ¡gina: Dashboard
if page == "ğŸ  Dashboard":
    # Header do Dashboard
    st.markdown('<h1 class="main-header">ğŸ›¡ï¸ N-BaIoT Intrusion Detection Lab</h1>', unsafe_allow_html=True)
    st.markdown("---")
    
    # Cards principais
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div style='background-color: #f0f2f6; padding: 2rem; border-radius: 10px; text-align: center; border: 2px solid #1f77b4;'>
            <h2 style='color: #1f77b4; margin-bottom: 1rem;'>ğŸ“¤</h2>
            <h3 style='color: #1f77b4; margin-bottom: 1rem;'>PrÃ©-processamento</h3>
            <p style='color: #666;'>Carregar dataset, visualizar, limpar e preparar dados</p>
        </div>
        """, unsafe_allow_html=True)
        if st.button("ğŸš€ Ir para PrÃ©-processamento", key="btn_preprocess", use_container_width=True):
            st.session_state.page_redirect = "ğŸ“¤ Upload & PrÃ©-processamento"
            st.rerun()
    
    with col2:
        st.markdown("""
        <div style='background-color: #f0f2f6; padding: 2rem; border-radius: 10px; text-align: center; border: 2px solid #1f77b4;'>
            <h2 style='color: #1f77b4; margin-bottom: 1rem;'>ğŸ¤–</h2>
            <h3 style='color: #1f77b4; margin-bottom: 1rem;'>Treinamento</h3>
            <p style='color: #666;'>Treinar modelos de ML e ajustar hiperparÃ¢metros</p>
        </div>
        """, unsafe_allow_html=True)
        if st.button("ğŸš€ Ir para Treinamento", key="btn_train", use_container_width=True):
            st.session_state.page_redirect = "ğŸ¤– Treinamento"
            st.rerun()
    
    with col3:
        st.markdown("""
        <div style='background-color: #f0f2f6; padding: 2rem; border-radius: 10px; text-align: center; border: 2px solid #1f77b4;'>
            <h2 style='color: #1f77b4; margin-bottom: 1rem;'>ğŸ“ˆ</h2>
            <h3 style='color: #1f77b4; margin-bottom: 1rem;'>Resultados</h3>
            <p style='color: #666;'>Visualizar mÃ©tricas e anÃ¡lises detalhadas</p>
        </div>
        """, unsafe_allow_html=True)
        if st.button("ğŸš€ Ver Resultados", key="btn_results", use_container_width=True):
            st.session_state.page_redirect = "ğŸ“ˆ Resultados"
            st.rerun()
    
    st.markdown("---")
    
    # Indicadores/EstatÃ­sticas
    st.subheader("ğŸ“Š Indicadores do Sistema")
    
    col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
    
    with col_stat1:
        if st.session_state.dataset_loaded and st.session_state.data is not None:
            n_samples = len(st.session_state.data)
            st.metric("ğŸ“¦ Amostras Carregadas", f"{n_samples:,}")
        else:
            st.metric("ğŸ“¦ Amostras Carregadas", "0")
    
    with col_stat2:
        if st.session_state.dataset_loaded and st.session_state.data is not None and 'device' in st.session_state.data.columns:
            n_devices = st.session_state.data['device'].nunique()
            st.metric("ğŸ“± Dispositivos", n_devices)
        else:
            st.metric("ğŸ“± Dispositivos", "0")
    
    with col_stat3:
        if st.session_state.model_trained:
            st.metric("âœ… Modelos Treinados", "1")
        else:
            st.metric("âœ… Modelos Treinados", "0")
    
    with col_stat4:
        if st.session_state.dataset_path:
            st.metric("ğŸ’¾ Dataset", "DisponÃ­vel")
        else:
            st.metric("ğŸ’¾ Dataset", "NÃ£o baixado")
    
    st.markdown("---")
    
    # Status e informaÃ§Ãµes
    st.subheader("â„¹ï¸ Status do Sistema")
    
    if st.session_state.dataset_path:
        st.success(f"âœ… **Dataset baixado!** LocalizaÃ§Ã£o: `{st.session_state.dataset_path}`")
    else:
        st.warning("âš ï¸ Dataset ainda nÃ£o foi baixado. VÃ¡ para 'PrÃ©-processamento' para baixar.")
    
    if st.session_state.dataset_loaded:
        st.success("âœ… **Dados carregados na memÃ³ria!**")
    else:
        st.info("â„¹ï¸ Dados ainda nÃ£o foram carregados. VÃ¡ para 'PrÃ©-processamento' para carregar.")
    
    if st.session_state.model_trained:
        st.success("âœ… **Modelo treinado!** VÃ¡ para 'Resultados' para ver mÃ©tricas.")
    else:
        st.info("â„¹ï¸ Nenhum modelo treinado ainda. VÃ¡ para 'Treinamento' para treinar um modelo.")
    
    # Redirecionamento se necessÃ¡rio
    if hasattr(st.session_state, 'page_redirect'):
        page = st.session_state.page_redirect
        del st.session_state.page_redirect

# PÃ¡gina: Upload & PrÃ©-processamento
elif page == "ğŸ“¤ Upload & PrÃ©-processamento":
    st.header("ğŸ“¤ Upload & PrÃ©-processamento")
    
    # SeÃ§Ã£o de carregamento
    st.subheader("ğŸ“¤ Carregamento")
    
    # OpÃ§Ãµes de carregamento
    with st.expander("âš™ï¸ OpÃ§Ãµes de Carregamento", expanded=True):
        st.markdown("### ğŸ“‹ ConfiguraÃ§Ãµes de Carregamento")
        
        # Descobre dispositivos disponÃ­veis
        available_devices = []
        device_names_preview = {}
        if st.session_state.dataset_path:
            try:
                available_devices, device_names_preview = get_available_devices(st.session_state.dataset_path)
            except:
                pass
        
        if available_devices:
            st.info(f"ğŸ“± **Dispositivos disponÃ­veis no dataset:** {len(available_devices)}")
            
            # Mostra lista de dispositivos disponÃ­veis
            device_list = []
            for dev_num in available_devices:
                dev_name = device_names_preview.get(dev_num, f"Device {dev_num}")
                device_list.append(f"{dev_name} (Device {dev_num})")
            
            st.markdown("**Dispositivos encontrados:**")
            for dev_info in device_list:
                st.markdown(f"- {dev_info}")
        
        # SeleÃ§Ã£o de dispositivos
        if available_devices:
            st.markdown("### ğŸ“± SeleÃ§Ã£o de Dispositivos")
            st.markdown("""
            **Como funciona:**
            - Cada dispositivo tem mÃºltiplos arquivos CSV (benign + diferentes tipos de ataque)
            - Ao selecionar um dispositivo, TODOS os seus arquivos serÃ£o carregados
            - Isso garante que vocÃª tenha dados completos de cada dispositivo
            """)
            
            # Multi-select de dispositivos
            device_options = []
            for dev_num in available_devices:
                dev_name = device_names_preview.get(dev_num, f"Device {dev_num}")
                device_options.append(f"{dev_name} (Device {dev_num})")
            
            selected_devices_display = st.multiselect(
                "Selecione os Dispositivos para Carregar:",
                device_options,
                default=device_options[:1] if device_options else [],  # Seleciona o primeiro por padrÃ£o
                help="Selecione um ou mais dispositivos. Cada dispositivo terÃ¡ TODOS os seus arquivos CSV carregados (benign + todos os tipos de ataque)."
            )
            
            # Extrai nÃºmeros dos dispositivos selecionados
            selected_devices = []
            for display_name in selected_devices_display:
                # Extrai o nÃºmero do dispositivo do nome (Ãºltimo nÃºmero entre parÃªnteses)
                import re
                match = re.search(r'Device (\d+)', display_name)
                if match:
                    selected_devices.append(int(match.group(1)))
            
            if not selected_devices:
                st.warning("âš ï¸ Selecione pelo menos um dispositivo para carregar.")
        else:
            selected_devices = None  # Carrega todos se nÃ£o conseguir detectar
            st.info("â„¹ï¸ NÃ£o foi possÃ­vel detectar dispositivos. Carregando todos os arquivos disponÃ­veis.")
        
        sample_size = st.number_input(
            "Amostra por arquivo (opcional, deixe 0 para carregar tudo)",
            min_value=0,
            max_value=1000000,
            value=0,
            step=10000,
            help="Se o dataset for muito grande, vocÃª pode carregar apenas uma amostra de cada arquivo para economizar memÃ³ria. 0 = carregar tudo. Recomendado: 0 (tudo) ou 50000-100000 para testes rÃ¡pidos."
        )
        if sample_size == 0:
            sample_size = None
        
        # Estimativa de memÃ³ria (se dispositivos selecionados)
        if selected_devices and available_devices:
            # Estima quantos arquivos serÃ£o carregados (cada dispositivo tem ~11 arquivos)
            estimated_files = len(selected_devices) * 11  # AproximaÃ§Ã£o: cada dispositivo tem ~11 arquivos
            if sample_size:
                estimated_rows = estimated_files * sample_size
                estimated_mb = (estimated_rows * 50) / (1024 * 1024)
                st.info(f"ğŸ’¾ **Estimativa:** ~{estimated_rows:,} linhas, ~{estimated_mb:.1f} MB de memÃ³ria")
            else:
                st.info(f"ğŸ’¾ **Nota:** Carregando dados de {len(selected_devices)} dispositivo(s). Cada dispositivo tem mÃºltiplos arquivos CSV (benign + ataques).")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # Verifica se pode carregar
        can_load = True
        if available_devices:
            if not selected_devices or len(selected_devices) == 0:
                can_load = False
                st.warning("âš ï¸ Selecione pelo menos um dispositivo para carregar.")
        
        if st.button("ğŸ”„ Carregar Dataset do Kaggle", type="primary", width='stretch', disabled=not can_load):
            progress_container = st.container()
            with progress_container:
                status_placeholder = st.empty()
                progress_bar = st.progress(0)
                
                try:
                    if selected_devices:
                        devices_str = ', '.join([device_names_preview.get(d, f"Device {d}") for d in selected_devices])
                        status_placeholder.info(f"ğŸ”„ Iniciando carregamento de {len(selected_devices)} dispositivo(s): {devices_str}...")
                    else:
                        status_placeholder.info("ğŸ”„ Iniciando carregamento de todos os dispositivos disponÃ­veis...")
                    progress_bar.progress(10)
                    
                    # Se o dataset jÃ¡ foi baixado, usa o caminho salvo
                    if st.session_state.dataset_path:
                        status_placeholder.info("ğŸ“‚ Usando dataset jÃ¡ baixado...")
                        progress_bar.progress(20)
                        # Carrega usando o caminho jÃ¡ baixado
                        df, dataset_path, device_names = load_dataset(
                            devices_to_load=selected_devices if selected_devices else None,
                            sample_size=sample_size,
                            dataset_path=st.session_state.dataset_path
                        )
                    else:
                        status_placeholder.info("ğŸ“¥ Fazendo download do dataset...")
                        progress_bar.progress(20)
                        # Faz download e carrega
                        df, dataset_path, device_names = load_dataset(
                            devices_to_load=selected_devices if selected_devices else None,
                            sample_size=sample_size
                        )
                        st.session_state.dataset_path = dataset_path
                    
                    # Salva os nomes dos dispositivos
                    st.session_state.device_names = device_names
                    
                    progress_bar.progress(80)
                    status_placeholder.info("âœ… Processando dados...")
                    
                    st.session_state.data = df
                    st.session_state.dataset_loaded = True
                    
                    progress_bar.progress(100)
                    status_placeholder.empty()
                    progress_bar.empty()
                    
                    # Mostra informaÃ§Ãµes detalhadas
                    st.success(f"âœ… **Dataset carregado com sucesso!**")
                    
                    col_info1, col_info2, col_info3 = st.columns(3)
                    with col_info1:
                        st.metric("Total de Linhas", f"{len(df):,}")
                    with col_info2:
                        st.metric("Total de Colunas", len(df.columns))
                    with col_info3:
                        memory_mb = df.memory_usage(deep=True).sum() / (1024**2)
                        st.metric("MemÃ³ria Usada", f"{memory_mb:.2f} MB")
                    
                    st.info(f"ğŸ“ **LocalizaÃ§Ã£o:** `{dataset_path}`")
                    
                    if selected_devices and len(selected_devices) < len(available_devices):
                        st.info(f"ğŸ’¡ **Dica:** VocÃª carregou {len(selected_devices)} dispositivo(s). Para mais dados, selecione mais dispositivos nas opÃ§Ãµes acima.")
                    
                except MemoryError as e:
                    progress_bar.empty()
                    status_placeholder.error("âŒ **Erro de MemÃ³ria**")
                    st.error("O dataset Ã© muito grande para a memÃ³ria disponÃ­vel.")
                    st.warning("**SoluÃ§Ãµes:**")
                    st.markdown("""
                    - Reduza o nÃºmero de arquivos (tente 1-3 arquivos)
                    - Use uma amostra menor (ex: 50000 linhas por arquivo)
                    - Feche outros aplicativos para liberar memÃ³ria
                    """)
                except Exception as e:
                    progress_bar.empty()
                    status_placeholder.error("âŒ **Erro ao carregar dataset**")
                    st.error(f"Erro: `{str(e)}`")
                    st.info("ğŸ’¡ Certifique-se de que suas credenciais do Kaggle estÃ£o configuradas corretamente.")
                    st.info("ğŸ’¡ **Dicas:**")
                    st.markdown("""
                    - Tente reduzir o nÃºmero de arquivos
                    - Use uma amostra menor (ex: 50000 linhas)
                    - Verifique sua conexÃ£o com a internet
                    """)
    
    # Mostra status do download automÃ¡tico
    if st.session_state.dataset_path and not st.session_state.dataset_loaded:
        st.info(f"ğŸ“¥ Dataset jÃ¡ foi baixado em: {st.session_state.dataset_path}")
        st.info("ğŸ’¡ Clique no botÃ£o acima para carregar os dados na memÃ³ria.")
    
    # SeÃ§Ã£o de visualizaÃ§Ã£o
    if st.session_state.dataset_loaded and st.session_state.data is not None:
        df = st.session_state.data
        
        st.subheader("2. InformaÃ§Ãµes do Dataset")
        
        # EstatÃ­sticas bÃ¡sicas
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total de Registros", f"{len(df):,}")
        with col2:
            st.metric("Total de Features", len(df.columns))
        with col3:
            st.metric("Valores Nulos", df.isnull().sum().sum())
        with col4:
            st.metric("MemÃ³ria Usada", f"{df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
        
        # VisualizaÃ§Ã£o dos dados
        st.subheader("3. VisualizaÃ§Ã£o dos Dados")
        
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‹ Primeiras Linhas", "ğŸ“Š EstatÃ­sticas", "ğŸ“ˆ DistribuiÃ§Ãµes", "ğŸ” InformaÃ§Ãµes"])
        
        with tab1:
            try:
                df_display = make_arrow_compatible(df.head(100))
                st.dataframe(df_display, width='stretch')
            except Exception as e:
                st.warning(f"Erro ao exibir dataframe: {str(e)}")
                st.text("Tentando exibir como texto...")
                st.text(str(df.head(100)))
        
        with tab2:
            try:
                desc_df = df.describe()
                # Converte todos os valores para float64 explÃ­cito
                desc_df = desc_df.astype('float64')
                st.dataframe(desc_df, width='stretch')
            except Exception as e:
                st.warning(f"Erro ao exibir estatÃ­sticas: {str(e)}")
                # Fallback: converte para string
                desc_df = df.describe()
                for col in desc_df.columns:
                    desc_df[col] = desc_df[col].astype(str)
                st.dataframe(desc_df, width='stretch')
        
        with tab3:
            # Seleciona colunas numÃ©ricas para visualizaÃ§Ã£o
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            if numeric_cols:
                selected_col = st.selectbox("Selecione uma coluna para visualizar:", numeric_cols[:20])
                if selected_col:
                    fig = px.histogram(df, x=selected_col, nbins=50, title=f"DistribuiÃ§Ã£o de {selected_col}")
                    st.plotly_chart(fig, width='stretch')
            else:
                st.warning("Nenhuma coluna numÃ©rica encontrada para visualizaÃ§Ã£o.")
        
        with tab4:
            st.text("InformaÃ§Ãµes do DataFrame:")
            try:
                buffer = StringIO()
                df.info(buf=buffer)
                st.text(buffer.getvalue())
            except Exception as e:
                st.warning(f"Erro ao exibir informaÃ§Ãµes: {str(e)}")
                st.text(f"Shape: {df.shape}")
                st.text(f"Colunas: {list(df.columns)}")
            
            st.text("\nTipos de Dados:")
            try:
                # Converte tipos para string para evitar problemas com PyArrow
                dtypes_df = df.dtypes.to_frame(name="Tipo")
                dtypes_df['Tipo'] = dtypes_df['Tipo'].astype(str)
                # Reseta o Ã­ndice para garantir compatibilidade
                dtypes_df = dtypes_df.reset_index()
                dtypes_df.columns = ['Coluna', 'Tipo']
                st.dataframe(dtypes_df, width='stretch')
            except Exception as e:
                st.warning(f"Erro ao exibir tipos: {str(e)}")
                # Fallback: exibe como texto
                for col in df.columns:
                    st.text(f"{col}: {str(df[col].dtype)}")
        
        # DetecÃ§Ã£o de coluna target
        st.subheader("4. ConfiguraÃ§Ã£o para Treinamento")
        
        # InformaÃ§Ãµes sobre o dataset N-BaIoT
        if 'label' in df.columns:
            unique_labels = df['label'].unique()
            label_counts = df['label'].value_counts()
            
            st.info("ğŸ“‹ **Sobre o Dataset N-BaIoT:**")
            st.markdown("""
            O dataset N-BaIoT contÃ©m trÃ¡fego de rede de dispositivos IoT:
            - **Benign**: TrÃ¡fego normal (sem ataque)
            - **Mirai**: Ataques do botnet Mirai (scan, ack, syn, udp, udpplain)
            - **Gafgyt (BASHLITE)**: Ataques do botnet Gafgyt (udp, junk, scan, tcp, combo)
            
            Os labels sÃ£o extraÃ­dos automaticamente do nome do arquivo.
            """)
            
            st.markdown("**Labels encontrados no dataset:**")
            label_info_df = pd.DataFrame({
                'Label': label_counts.index,
                'Amostras': label_counts.values,
                '%': (label_counts.values / len(df) * 100).round(2)
            })
            st.dataframe(make_arrow_compatible(label_info_df), width='stretch')
        
        # InformaÃ§Ãµes sobre dispositivos
        if 'device' in df.columns:
            unique_devices = sorted(df['device'].unique())
            device_counts = df['device'].value_counts().sort_index()
            device_names = getattr(st.session_state, 'device_names', {})
            
            st.markdown("**ğŸ“± Dispositivos encontrados no dataset:**")
            
            # Cria DataFrame com nomes dos dispositivos
            device_display_names = []
            for d in device_counts.index:
                device_name = device_names.get(d, f"Device {d}")
                device_display_names.append(f"{device_name} (Device {d})")
            
            device_info_df = pd.DataFrame({
                'Dispositivo': device_display_names,
                'Amostras': device_counts.values,
                '%': (device_counts.values / len(df) * 100).round(2)
            })
            st.dataframe(make_arrow_compatible(device_info_df), width='stretch')
            
            # OpÃ§Ã£o de treinar por dispositivo
            st.markdown("---")
            st.subheader("ğŸ¯ Modo de Treinamento")
            
            # Se houver mÃºltiplos dispositivos, permite escolher
            if len(unique_devices) > 1:
                train_mode = st.radio(
                    "Escolha a estratÃ©gia de treinamento:",
                    ["Treinar por Dispositivo (Recomendado)", "Treinar com Todos os Dispositivos"],
                    help="Treinar por dispositivo melhora a sensibilidade. Treinar com todos combina os dados de todos os dispositivos.",
                    index=0
                )
                
                train_by_device = (train_mode == "Treinar por Dispositivo (Recomendado)")
            else:
                train_by_device = True
                st.info(f"â„¹ï¸ Apenas 1 dispositivo encontrado. Treinando modelo especÃ­fico para este dispositivo.")
            
            if train_by_device:
                # Cria lista de opÃ§Ãµes com nomes dos dispositivos
                device_options = []
                for d in unique_devices:
                    device_name = device_names.get(d, f"Device {d}")
                    device_options.append(f"{device_name} (Device {d})")
                
                selected_device_display = st.selectbox(
                    "Selecione o Dispositivo para Treinar:",
                    device_options,
                    format_func=lambda x: f"{x} - {device_counts[unique_devices[device_options.index(x)]]:,} amostras",
                    help="Cada dispositivo terÃ¡ seu prÃ³prio modelo treinado apenas com seus dados."
                )
                
                # Extrai o nÃºmero do dispositivo da seleÃ§Ã£o
                selected_device = unique_devices[device_options.index(selected_device_display)]
                st.session_state.selected_device = selected_device
                st.session_state.train_by_device = True
                
                # Mostra informaÃ§Ãµes sobre o dispositivo selecionado
                device_df = df[df['device'] == selected_device]
                device_labels = device_df['label'].value_counts()
                device_name = device_names.get(selected_device, f"Device {selected_device}")
                
                st.success(f"âœ… **{device_name} (Device {selected_device}) selecionado:** {len(device_df):,} amostras")
                st.markdown(f"**DistribuiÃ§Ã£o de labels no {device_name}:**")
                device_label_df = pd.DataFrame({
                    'Label': device_labels.index,
                    'Amostras': device_labels.values,
                    '%': (device_labels.values / len(device_df) * 100).round(2)
                })
                st.dataframe(make_arrow_compatible(device_label_df), width='stretch')
            else:
                st.session_state.train_by_device = False
                st.session_state.selected_device = None
                
                # Mostra informaÃ§Ãµes sobre todos os dispositivos combinados
                total_samples = len(df)
                all_labels = df['label'].value_counts()
                
                st.success(f"âœ… **Treinando com todos os {len(unique_devices)} dispositivos combinados:** {total_samples:,} amostras")
                st.markdown("**DistribuiÃ§Ã£o de labels (todos os dispositivos):**")
                all_labels_df = pd.DataFrame({
                    'Label': all_labels.index,
                    'Amostras': all_labels.values,
                    '%': (all_labels.values / total_samples * 100).round(2)
                })
                st.dataframe(make_arrow_compatible(all_labels_df), width='stretch')
                
                st.info("ğŸ’¡ **Vantagem:** Mais dados para treinar, mas pode ter menor sensibilidade por dispositivo.")
        
        # Encontra colunas adequadas para classificaÃ§Ã£o
        suitable_cols = find_suitable_target_columns(df)
        suitable_targets = [col['column'] for col in suitable_cols if col['is_suitable']]
        recommended_targets = [col['column'] for col in suitable_cols if col['is_suitable'] and col['has_keyword']]
        
        # Mostra informaÃ§Ãµes sobre colunas adequadas
        if recommended_targets:
            st.success(f"âœ… **Colunas recomendadas encontradas:** {', '.join(recommended_targets[:5])}")
            default_target = recommended_targets[0]
        elif suitable_targets:
            st.info(f"ğŸ’¡ **Colunas adequadas encontradas:** {', '.join(suitable_targets[:5])}")
            default_target = suitable_targets[0]
        else:
            st.warning("âš ï¸ **AtenÃ§Ã£o:** Nenhuma coluna claramente adequada para classificaÃ§Ã£o foi encontrada.")
            st.info("ğŸ’¡ VocÃª pode selecionar manualmente uma coluna, mas verifique se ela tem poucos valores Ãºnicos (classes).")
            # Tenta encontrar por keywords mesmo que nÃ£o seja "suitable"
            possible_targets = [col['column'] for col in suitable_cols if col['has_keyword']]
            if possible_targets:
                default_target = possible_targets[0]
            else:
                default_target = df.columns[-1]
        
        # Tabela com informaÃ§Ãµes das colunas
        with st.expander("ğŸ“Š Ver todas as colunas e adequaÃ§Ã£o para classificaÃ§Ã£o", expanded=False):
            cols_info_df = pd.DataFrame(suitable_cols)
            cols_info_df['Status'] = cols_info_df.apply(
                lambda x: 'âœ… Recomendada' if x['is_suitable'] and x['has_keyword'] 
                else 'âœ… Adequada' if x['is_suitable'] 
                else 'âš ï¸ Muitos valores Ãºnicos' if x['unique_count'] > 50 
                else 'âŒ Poucos valores Ãºnicos',
                axis=1
            )
            display_df = cols_info_df[['column', 'unique_count', 'percentage', 'Status']].copy()
            display_df.columns = ['Coluna', 'Valores Ãšnicos', '% Ãšnicos', 'Status']
            # Garante que todos os valores numÃ©ricos sejam compatÃ­veis
            display_df['Valores Ãšnicos'] = display_df['Valores Ãšnicos'].astype('int64')
            display_df['% Ãšnicos'] = display_df['% Ãšnicos'].astype('float64')
            st.dataframe(display_df, width='stretch')
        
        # Selectbox com todas as colunas, mas destacando as adequadas
        all_columns = df.columns.tolist()
        target_column = st.selectbox(
            "Selecione a coluna target (classe):",
            all_columns,
            index=all_columns.index(default_target) if default_target in all_columns else 0,
            help="Selecione uma coluna com poucos valores Ãºnicos (classes categÃ³ricas). Colunas recomendadas aparecem primeiro na lista acima."
        )
        
        # Mostra distribuiÃ§Ã£o da classe target
        if target_column:
            unique_count = df[target_column].nunique()
            total_count = len(df[target_column].dropna())
            percentage = (unique_count / total_count * 100) if total_count > 0 else 0
            
            # ValidaÃ§Ã£o visual
            if unique_count > max(50, total_count * 0.5):
                st.error(f"âš ï¸ **AtenÃ§Ã£o:** A coluna '{target_column}' tem {unique_count} valores Ãºnicos ({percentage:.2f}% dos dados). Isso parece ser uma variÃ¡vel contÃ­nua (regressÃ£o), nÃ£o classificaÃ§Ã£o.")
                st.warning("Por favor, selecione uma coluna diferente com poucos valores Ãºnicos (classes categÃ³ricas).")
            elif unique_count < 2:
                st.error(f"âš ï¸ **AtenÃ§Ã£o:** A coluna '{target_column}' tem menos de 2 valores Ãºnicos. NÃ£o Ã© possÃ­vel fazer classificaÃ§Ã£o.")
            else:
                st.success(f"âœ… Coluna adequada para classificaÃ§Ã£o: {unique_count} classes distintas")
            
            st.write(f"**DistribuiÃ§Ã£o da classe '{target_column}':**")
            class_dist = df[target_column].value_counts()
            
            # Limita a exibiÃ§Ã£o se houver muitas classes
            if len(class_dist) > 20:
                st.info(f"Mostrando apenas as 20 classes mais frequentes (total: {len(class_dist)} classes)")
                class_dist_display = class_dist.head(20)
            else:
                class_dist_display = class_dist
            
            col1, col2 = st.columns([2, 1])
            with col1:
                fig = px.bar(x=class_dist_display.index.astype(str), y=class_dist_display.values,
                           labels={'x': target_column, 'y': 'FrequÃªncia'},
                           title=f"DistribuiÃ§Ã£o das Classes ({len(class_dist)} classes)")
                st.plotly_chart(fig, width='stretch')
            with col2:
                freq_df = class_dist_display.to_frame(name="FrequÃªncia")
                freq_df['FrequÃªncia'] = freq_df['FrequÃªncia'].astype('int64')
                st.dataframe(freq_df, width='stretch')
        
        st.session_state.target_column = target_column
        
        # BotÃ£o para ir para treinamento
        st.markdown("---")
        if st.button("â¡ï¸ Ir para Treinamento", type="primary", use_container_width=True):
            st.session_state.page_redirect = "ğŸ¤– Treinamento"
            st.rerun()

# PÃ¡gina: Treinamento
elif page == "ğŸ¤– Treinamento":
    st.header("ğŸ¤– Treinamento dos Modelos")
    
    if not st.session_state.dataset_loaded or st.session_state.data is None:
        st.warning("âš ï¸ Por favor, carregue o dataset primeiro na pÃ¡gina 'Upload & PrÃ©-processamento'")
        if st.button("ğŸ“¤ Ir para PrÃ©-processamento"):
            st.session_state.page_redirect = "ğŸ“¤ Upload & PrÃ©-processamento"
            st.rerun()
    else:
        df = st.session_state.data
        
        # ========== SEÃ‡ÃƒO DE TREINAMENTO ==========
        st.subheader("ğŸ¯ Escolher Tipo de Modelo")
        
        # SeleÃ§Ã£o do algoritmo
        algorithm = st.radio(
            "Selecione o Algoritmo de Machine Learning:",
            ["Random Forest", "XGBoost"],
            help="Escolha o algoritmo que deseja usar para classificaÃ§Ã£o",
            horizontal=True
        )
        
        st.session_state.selected_algorithm = algorithm.lower().replace(" ", "_")
        
        # ConfiguraÃ§Ã£o de divisÃ£o de dados
        st.subheader("âš™ï¸ ConfiguraÃ§Ãµes do Modelo")
        test_size = st.slider(
            "ProporÃ§Ã£o de Dados para Teste",
            min_value=0.1,
            max_value=0.5,
            value=0.2,
            step=0.05,
            help="ProporÃ§Ã£o do dataset que serÃ¡ usado para teste.",
            key="test_size_training"
        )
        
        # HiperparÃ¢metros especÃ­ficos por algoritmo
        st.subheader("âš™ï¸ HiperparÃ¢metros")
        
        # InformaÃ§Ãµes sobre hiperparÃ¢metros recomendados
        with st.expander("ğŸ’¡ Valores Recomendados para N-BaIoT", expanded=False):
            st.markdown("""
            **Baseado em pesquisas e melhores prÃ¡ticas para o dataset N-BaIoT:**
            
            **Random Forest:**
            - **n_estimators**: 50-200 (valores menores reduzem overfitting)
            - **max_depth**: 10-20 (profundidade moderada)
            - **min_samples_split**: 2-5
            - **min_samples_leaf**: 1-2
            
            **XGBoost:**
            - **n_estimators**: 50-200
            - **max_depth**: 3-8 (valores menores sÃ£o mais conservadores)
            - **learning_rate**: 0.01-0.1 (valores menores = menos overfitting)
            - **subsample**: 0.7-0.9 (reduz overfitting)
            - **colsample_bytree**: 0.7-0.9
            
            **ğŸ’¡ Dica:** Se vocÃª obteve 0.93 com parÃ¢metros menores, isso indica que valores mais conservadores 
            estÃ£o funcionando melhor para evitar overfitting. Continue experimentando com valores menores!
            """)
        
        if algorithm == "Random Forest":
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### ParÃ¢metros do Random Forest")
                
                n_estimators = st.slider(
                    "NÃºmero de Estimadores (Ã¡rvores)",
                    min_value=10,
                    max_value=500,
                    value=100,
                    step=10,
                    help="NÃºmero de Ã¡rvores na floresta. Valores menores (50-150) sÃ£o recomendados para evitar overfitting no N-BaIoT."
                )
                
                max_depth = st.slider(
                    "Profundidade MÃ¡xima",
                    min_value=1,
                    max_value=50,
                    value=15,
                    step=1,
                    help="Profundidade mÃ¡xima das Ã¡rvores. Valores entre 10-20 sÃ£o recomendados. Valores menores (10-15) reduzem overfitting."
                )
                
                if max_depth == 50:
                    max_depth = None  # Sem limite de profundidade
            
            with col2:
                st.markdown("#### ParÃ¢metros de DivisÃ£o")
                
                min_samples_split = st.slider(
                    "MÃ­nimo de Amostras para Split",
                    min_value=2,
                    max_value=20,
                    value=5,
                    step=1,
                    help="NÃºmero mÃ­nimo de amostras necessÃ¡rias para dividir um nÃ³ interno. Valores maiores (3-5) reduzem overfitting."
                )
                
                min_samples_leaf = st.slider(
                    "MÃ­nimo de Amostras por Folha",
                    min_value=1,
                    max_value=10,
                    value=2,
                    step=1,
                    help="NÃºmero mÃ­nimo de amostras necessÃ¡rias em uma folha. Valores maiores (2-4) reduzem overfitting."
                )
                
                criterion = st.selectbox(
                    "CritÃ©rio de DivisÃ£o",
                    ["gini", "entropy"],
                    help="FunÃ§Ã£o para medir a qualidade de uma divisÃ£o. 'gini' para impureza de Gini, 'entropy' para ganho de informaÃ§Ã£o."
                )
            
            hyperparams = {
                'n_estimators': n_estimators,
                'max_depth': max_depth,
                'min_samples_split': min_samples_split,
                'min_samples_leaf': min_samples_leaf,
                'criterion': criterion
            }
            
        elif algorithm == "XGBoost":
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### ParÃ¢metros do XGBoost")
                
                n_estimators = st.slider(
                    "NÃºmero de Estimadores (Ã¡rvores)",
                    min_value=10,
                    max_value=500,
                    value=100,
                    step=10,
                    help="NÃºmero de Ã¡rvores no modelo. Valores menores (50-150) sÃ£o recomendados para evitar overfitting."
                )
                
                max_depth = st.slider(
                    "Profundidade MÃ¡xima",
                    min_value=1,
                    max_value=20,
                    value=5,
                    step=1,
                    help="Profundidade mÃ¡xima das Ã¡rvores. Valores entre 3-8 sÃ£o recomendados. Valores menores reduzem overfitting."
                )
                
                learning_rate = st.slider(
                    "Taxa de Aprendizado (Learning Rate)",
                    min_value=0.01,
                    max_value=1.0,
                    value=0.05,
                    step=0.01,
                    help="Taxa de aprendizado. Valores menores (0.01-0.1) sÃ£o mais conservadores e reduzem overfitting."
                )
            
            with col2:
                st.markdown("#### ParÃ¢metros de RegularizaÃ§Ã£o")
                
                subsample = st.slider(
                    "Subsample",
                    min_value=0.1,
                    max_value=1.0,
                    value=0.8,
                    step=0.1,
                    help="ProporÃ§Ã£o de amostras usadas para treinar cada Ã¡rvore. Valores entre 0.7-0.9 reduzem overfitting."
                )
                
                colsample_bytree = st.slider(
                    "Colsample by Tree",
                    min_value=0.1,
                    max_value=1.0,
                    value=0.8,
                    step=0.1,
                    help="ProporÃ§Ã£o de features usadas para cada Ã¡rvore. Valores entre 0.7-0.9 sÃ£o recomendados."
                )
                
                min_child_weight = st.slider(
                    "MÃ­nimo Child Weight",
                    min_value=1,
                    max_value=10,
                    value=1,
                    step=1,
                    help="Peso mÃ­nimo necessÃ¡rio em uma folha."
                )
            
            hyperparams = {
                'n_estimators': n_estimators,
                'max_depth': max_depth,
                'learning_rate': learning_rate,
                'subsample': subsample,
                'colsample_bytree': colsample_bytree,
                'min_child_weight': min_child_weight
            }
        
        # EstratÃ©gia de treino
        st.subheader("ğŸ§ª EstratÃ©gia de Treino")
        
        # ConfiguraÃ§Ã£o de divisÃ£o de dados (jÃ¡ definida acima, apenas mostra o valor)
        st.info(f"ProporÃ§Ã£o de dados para teste: {test_size*100:.0f}%")
        
        # ValidaÃ§Ã£o da coluna target
        st.subheader("ğŸ¯ ValidaÃ§Ã£o da Coluna Target")
        
        target_col = getattr(st.session_state, 'target_column', None)
        if target_col is None:
            # Usa a funÃ§Ã£o de detecÃ§Ã£o melhorada
            suitable_cols = find_suitable_target_columns(df)
            recommended = [col['column'] for col in suitable_cols if col['is_suitable'] and col['has_keyword']]
            if recommended:
                target_col = recommended[0]
            else:
                suitable = [col['column'] for col in suitable_cols if col['is_suitable']]
                target_col = suitable[0] if suitable else None
        
        # Se nÃ£o encontrou uma coluna adequada, mostra aviso mas nÃ£o para
        if target_col is None:
            st.error("âš ï¸ **Nenhuma coluna target adequada foi selecionada!**")
            st.warning("Por favor, selecione uma coluna adequada para classificaÃ§Ã£o na pÃ¡gina 'Upload & PrÃ©-processamento'.")
            if st.button("ğŸ“¤ Ir para PrÃ©-processamento", key="btn_go_preprocess"):
                st.session_state.page_redirect = "ğŸ“¤ Upload & PrÃ©-processamento"
                st.rerun()
            target_col_valid = False
        elif target_col not in df.columns:
            st.error(f"âš ï¸ **Coluna '{target_col}' nÃ£o encontrada no dataset!**")
            target_col_valid = False
        else:
            target_col_valid = True
        
        if target_col_valid and target_col and target_col in df.columns:
            unique_count = df[target_col].nunique()
            total_count = len(df[target_col].dropna())
            
            col_val1, col_val2, col_val3 = st.columns(3)
            with col_val1:
                st.metric("Coluna Target", target_col)
            with col_val2:
                st.metric("Valores Ãšnicos", unique_count)
            with col_val3:
                percentage = (unique_count / total_count * 100) if total_count > 0 else 0
                st.metric("% Ãšnicos", f"{percentage:.2f}%")
            
            # ValidaÃ§Ã£o
            if unique_count > max(50, total_count * 0.5):
                st.error("âŒ **ERRO:** Esta coluna NÃƒO Ã© adequada para classificaÃ§Ã£o!")
                st.warning(f"""
                **Problema:** A coluna '{target_col}' tem {unique_count} valores Ãºnicos ({percentage:.1f}% dos dados).
                Isso indica uma variÃ¡vel contÃ­nua (regressÃ£o), nÃ£o classificaÃ§Ã£o.
                
                **SoluÃ§Ã£o:** 
                1. VÃ¡ para a pÃ¡gina 'Upload & PrÃ©-processamento' e selecione uma coluna adequada
                2. Selecione uma coluna marcada como "âœ… Recomendada" ou "âœ… Adequada"
                3. Colunas com poucos valores Ãºnicos (idealmente < 50) sÃ£o adequadas para classificaÃ§Ã£o
                """)
                st.info("ğŸ’¡ **Dica:** O dataset N-BaIoT geralmente tem uma coluna 'label' criada automaticamente do nome do arquivo. Procure por essa coluna!")
                target_col_valid = False
            elif unique_count < 2:
                st.error("âš ï¸ **AtenÃ§Ã£o:** Esta coluna tem menos de 2 valores Ãºnicos. NÃ£o Ã© possÃ­vel fazer classificaÃ§Ã£o.")
                target_col_valid = False
            else:
                st.success(f"âœ… Coluna adequada para classificaÃ§Ã£o ({unique_count} classes)")
                # Mostra uma prÃ©via das classes
                if unique_count <= 20:
                    class_preview = df[target_col].value_counts().head(10)
                    st.info(f"**Classes encontradas:** {', '.join([str(x) for x in class_preview.index[:10]])}")
                target_col_valid = True
        else:
            target_col_valid = False
        
        # BotÃ£o de treinamento (sempre visÃ­vel)
        st.markdown("---")
        st.subheader("ğŸš€ Treinar Modelo")
        
        # Verifica se pode treinar
        can_train = target_col_valid and target_col is not None and target_col in df.columns
        
        if not can_train:
            st.warning("âš ï¸ Por favor, configure uma coluna target vÃ¡lida antes de treinar.")
            if st.button("ğŸ“¤ Ir para PrÃ©-processamento", key="btn_go_preprocess2"):
                st.session_state.page_redirect = "ğŸ“¤ Upload & PrÃ©-processamento"
                st.rerun()
        else:
            if st.button("ğŸš€ Treinar Modelo", type="primary", use_container_width=True, key="btn_train_model"):
                with st.spinner("PrÃ©-processando dados e treinando modelo... Isso pode levar alguns minutos."):
                    try:
                        # PrÃ©-processamento
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        status_text.text("PrÃ©-processando dados...")
                        progress_bar.progress(20)
                        
                        # Filtra por dispositivo se o modo "treinar por dispositivo" estiver ativado
                        train_by_device = getattr(st.session_state, 'train_by_device', False)
                        selected_device = getattr(st.session_state, 'selected_device', None)
                        
                        df_to_use = df.copy()
                        if train_by_device and selected_device is not None and 'device' in df.columns:
                            df_to_use = df[df['device'] == selected_device].copy()
                            status_text.text(f"Filtrando dados do Device {selected_device}...")
                            st.info(f"ğŸ“± **Treinando modelo apenas para Device {selected_device}** ({len(df_to_use):,} amostras)")
                            progress_bar.progress(25)
                        
                        target_col = getattr(st.session_state, 'target_column', None)
                        if target_col is None:
                            # Usa a funÃ§Ã£o de detecÃ§Ã£o melhorada
                            suitable_cols = find_suitable_target_columns(df_to_use)
                            recommended = [col['column'] for col in suitable_cols if col['is_suitable'] and col['has_keyword']]
                            if recommended:
                                target_col = recommended[0]
                            else:
                                suitable = [col['column'] for col in suitable_cols if col['is_suitable']]
                                target_col = suitable[0] if suitable else df_to_use.columns[-1]
                        
                        # ValidaÃ§Ã£o prÃ©via antes de processar
                        if target_col and target_col in df_to_use.columns:
                            unique_count = df_to_use[target_col].nunique()
                            total_count = len(df_to_use[target_col].dropna())
                            
                            if unique_count > max(50, total_count * 0.5):
                                raise ValueError(
                                    f"A coluna '{target_col}' selecionada tem {unique_count} valores Ãºnicos ({unique_count/total_count*100:.1f}% dos dados). "
                                    f"Isso Ã© uma variÃ¡vel contÃ­nua (regressÃ£o), nÃ£o classificaÃ§Ã£o.\n\n"
                                    f"Por favor, volte para a pÃ¡gina 'ExploraÃ§Ã£o de Dados' e selecione uma coluna adequada para classificaÃ§Ã£o:\n"
                                    f"- Colunas com poucos valores Ãºnicos (idealmente < 50)\n"
                                    f"- Colunas categÃ³ricas (strings) ou inteiros discretos\n"
                                    f"- Exemplos: 'label', 'class', ou outras colunas com poucos valores distintos"
                                )
                        
                        X_train, X_test, y_train, y_test, scaler, label_encoder = preprocess_data(
                            df_to_use, target_column=target_col, test_size=test_size
                        )
                        
                        # Salva informaÃ§Ã£o do dispositivo usado
                        if train_by_device and selected_device is not None:
                            st.session_state.trained_device = selected_device
                        
                        # Mostra informaÃ§Ãµes sobre o prÃ©-processamento
                        with st.expander("ğŸ“Š InformaÃ§Ãµes do PrÃ©-processamento", expanded=False):
                            col_info1, col_info2, col_info3, col_info4 = st.columns(4)
                            with col_info1:
                                st.metric("Features", len(X_train.columns))
                            with col_info2:
                                st.metric("Treino", f"{len(X_train):,}")
                            with col_info3:
                                st.metric("Teste", f"{len(X_test):,}")
                            with col_info4:
                                n_classes = len(np.unique(y_train))
                                st.metric("Classes", n_classes)
                            
                            # DistribuiÃ§Ã£o das classes
                            st.markdown("**DistribuiÃ§Ã£o das Classes no Treino:**")
                            train_class_dist = pd.Series(y_train).value_counts().sort_index()
                            st.dataframe(train_class_dist.to_frame(name="Amostras"), width='stretch')
                            
                            # Avisos sobre possÃ­veis problemas
                            if len(X_train) < 100:
                                st.warning("âš ï¸ Dataset de treino muito pequeno (< 100 amostras). MÃ©tricas podem nÃ£o ser confiÃ¡veis.")
                            
                            if n_classes < 3:
                                st.info(f"â„¹ï¸ Problema com {n_classes} classe(s). Poucas classes podem facilitar a classificaÃ§Ã£o.")
                            
                            train_min = train_class_dist.min()
                            train_max = train_class_dist.max()
                            if train_min / train_max < 0.1:
                                st.warning("âš ï¸ Dataset muito desbalanceado! A classe menor tem menos de 10% das amostras da classe maior.")
                        
                        st.session_state.X_train = X_train
                        st.session_state.X_test = X_test
                        st.session_state.y_train = y_train
                        st.session_state.y_test = y_test
                        st.session_state.scaler = scaler
                        st.session_state.label_encoder = label_encoder
                        
                        algorithm_name = st.session_state.selected_algorithm
                        algorithm_display = algorithm  # Nome para exibiÃ§Ã£o
                        status_text.text(f"Treinando modelo {algorithm_display}...")
                        progress_bar.progress(50)
                        
                        # Treinamento com algoritmo selecionado
                        model = train_model(algorithm_name, X_train, y_train, **hyperparams)
                        
                        # Salva informaÃ§Ãµes do algoritmo usado
                        st.session_state.algorithm_display = algorithm_display
                        
                        st.session_state.model = model
                        
                        status_text.text("Avaliando modelo...")
                        progress_bar.progress(80)
                        
                        # AvaliaÃ§Ã£o (inclui mÃ©tricas de treino para detectar overfitting)
                        results = evaluate_model(model, X_test, y_test, label_encoder, X_train, y_train)
                        st.session_state.results = results
                        st.session_state.model_trained = True
                        
                        progress_bar.progress(100)
                        status_text.text("âœ… Modelo treinado com sucesso!")
                        
                        time.sleep(0.5)
                        progress_bar.empty()
                        status_text.empty()
                        
                        st.success("âœ… Modelo treinado e avaliado com sucesso!")
                        st.balloons()
                        
                        # OpÃ§Ã£o de salvar modelo
                        st.markdown("---")
                        st.subheader("ğŸ’¾ Salvar Modelo")
                        
                        col_save1, col_save2 = st.columns(2)
                        with col_save1:
                            device_names_save = getattr(st.session_state, 'device_names', {})
                            train_by_device_save = getattr(st.session_state, 'train_by_device', False)
                            selected_device_save = getattr(st.session_state, 'selected_device', None)
                            
                            if train_by_device_save and selected_device_save is not None:
                                device_name_save = device_names_save.get(selected_device_save, f"Device{selected_device_save}")
                                default_name = f"{algorithm_display}_{device_name_save.replace(' ', '_')}"
                            else:
                                default_name = f"{algorithm_display}_all_devices"
                            model_name = st.text_input("Nome do modelo (opcional):", value=default_name, key="model_name_input")
                        with col_save2:
                            if st.button("ğŸ’¾ Salvar Modelo", use_container_width=True):
                                try:
                                    import joblib
                                    import os
                                    
                                    # Cria diretÃ³rio de modelos se nÃ£o existir
                                    models_dir = "saved_models"
                                    os.makedirs(models_dir, exist_ok=True)
                                    
                                    # Salva o modelo
                                    model_path = os.path.join(models_dir, f"{model_name}.pkl")
                                    joblib.dump({
                                        'model': model,
                                        'scaler': scaler,
                                        'label_encoder': label_encoder,
                                        'algorithm': algorithm_display,
                                        'hyperparams': hyperparams,
                                        'device': selected_device if train_by_device and selected_device else None
                                    }, model_path)
                                    
                                    st.success(f"âœ… Modelo salvo em: `{model_path}`")
                                    
                                    # BotÃ£o de download
                                    with open(model_path, 'rb') as f:
                                        st.download_button(
                                            label="ğŸ“¥ Download do Modelo",
                                            data=f.read(),
                                            file_name=f"{model_name}.pkl",
                                            mime="application/octet-stream"
                                        )
                                except Exception as e:
                                    st.error(f"âŒ Erro ao salvar modelo: {str(e)}")
                    
                    except ValueError as e:
                        error_msg = str(e)
                        if "least populated class" in error_msg or "minimum number of groups" in error_msg:
                            st.error("âŒ **Erro: Classes com poucas amostras**")
                            st.warning("""
                            O dataset tem classes com menos de 2 amostras, o que impede a divisÃ£o estratificada.
                            
                            **SoluÃ§Ãµes:**
                            - Tente aumentar o nÃºmero de arquivos carregados
                            - Aumente o tamanho da amostra por arquivo
                            - O cÃ³digo tentarÃ¡ automaticamente usar divisÃ£o sem estratificaÃ§Ã£o
                            """)
                            st.info("ğŸ’¡ Tente novamente com mais dados ou verifique a distribuiÃ§Ã£o das classes na pÃ¡gina 'Upload & PrÃ©-processamento'")
                        elif "regressÃ£o" in error_msg.lower() or "regression" in error_msg.lower() or "valores Ãºnicos" in error_msg.lower():
                            st.error("âŒ **Erro: VariÃ¡vel Target Incorreta**")
                            st.warning("""
                            A coluna selecionada como target parece ser uma variÃ¡vel contÃ­nua (regressÃ£o), 
                            mas estamos usando um modelo de classificaÃ§Ã£o que requer valores categÃ³ricos.
                            
                            **O que fazer:**
                            - VÃ¡ para a pÃ¡gina 'Upload & PrÃ©-processamento'
                            - Verifique a distribuiÃ§Ã£o da coluna target
                            - Selecione uma coluna com valores categÃ³ricos (poucos valores Ãºnicos)
                            - Exemplos: 'label', 'class', 'attack', 'type', etc.
                            """)
                            st.info(f"ğŸ’¡ **Detalhes:** {error_msg}")
                        elif "apenas" in error_msg.lower() and "classe" in error_msg.lower():
                            st.error("âŒ **Erro: Poucas Classes**")
                            st.warning("""
                            ApÃ³s o prÃ©-processamento, restaram menos de 2 classes no dataset.
                            
                            **SoluÃ§Ãµes:**
                            - Aumente o nÃºmero de arquivos carregados
                            - Verifique se a coluna target estÃ¡ correta
                            - Aumente o tamanho da amostra
                            """)
                        else:
                            st.error(f"âŒ Erro ao treinar modelo: {error_msg}")
                        st.exception(e)
                    except Exception as e:
                        st.error(f"âŒ Erro ao treinar modelo: {str(e)}")
                        st.exception(e)
        
        # Mostra informaÃ§Ãµes do modelo se jÃ¡ foi treinado
        if st.session_state.model_trained:
            st.subheader("10. InformaÃ§Ãµes do Modelo Treinado")
            
            model = st.session_state.model
            algorithm_display = getattr(st.session_state, 'algorithm_display', 'Modelo')
            
            st.success(f"âœ… **Modelo {algorithm_display} treinado com sucesso!**")
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Algoritmo", algorithm_display)
                if hasattr(model, 'n_estimators'):
                    st.metric("NÃºmero de Estimadores", model.n_estimators)
                if hasattr(model, 'max_depth'):
                    st.metric("Profundidade MÃ¡xima", str(model.max_depth) if model.max_depth else "Sem limite")
            
            with col2:
                if hasattr(model, 'criterion'):
                    st.metric("CritÃ©rio", model.criterion)
                if hasattr(model, 'learning_rate'):
                    st.metric("Learning Rate", model.learning_rate)
            
            st.info("ğŸ’¡ VÃ¡ para a pÃ¡gina 'Resultados' para ver mÃ©tricas detalhadas e visualizaÃ§Ãµes.")

# PÃ¡gina: Resultados
elif page == "ğŸ“ˆ Resultados":
    st.header("ğŸ“ˆ Resultados e AvaliaÃ§Ã£o")
    
    if not st.session_state.model_trained or st.session_state.results is None:
        st.warning("âš ï¸ Por favor, treine o modelo primeiro na pÃ¡gina 'Dados e Treinamento'")
    else:
        results = st.session_state.results
        algorithm_display = getattr(st.session_state, 'algorithm_display', 'Modelo')
        
        # InformaÃ§Ãµes do modelo
        st.subheader("1. InformaÃ§Ãµes do Modelo")
        col_info1, col_info2 = st.columns(2)
        with col_info1:
            st.metric("Algoritmo Utilizado", algorithm_display)
            # Mostra dispositivo se foi treinado por dispositivo
            trained_device = getattr(st.session_state, 'trained_device', None)
            device_names = getattr(st.session_state, 'device_names', {})
            train_by_device = getattr(st.session_state, 'train_by_device', False)
            
            if train_by_device and trained_device is not None:
                device_name = device_names.get(trained_device, f"Device {trained_device}")
                st.info(f"ğŸ“± Modelo treinado para **{device_name} (Device {trained_device})** (modelo por dispositivo)")
            elif not train_by_device:
                st.info(f"ğŸ“± Modelo treinado com **todos os dispositivos combinados**")
        with col_info2:
            model = st.session_state.model
            if hasattr(model, 'n_estimators'):
                st.metric("NÃºmero de Estimadores", model.n_estimators)
        
        # MÃ©tricas principais
        st.subheader("2. MÃ©tricas de Desempenho")
        
        # Verifica se hÃ¡ mÃ©tricas de treino para comparaÃ§Ã£o
        has_train_metrics = results.get('train_metrics') is not None
        
        if has_train_metrics:
            train_metrics = results['train_metrics']
            
            st.markdown("### ğŸ“Š ComparaÃ§Ã£o: Treino vs Teste")
            st.markdown("**A diferenÃ§a entre treino e teste indica overfitting:**")
            st.markdown("- **DiferenÃ§a < 2%**: Modelo generaliza bem âœ…")
            st.markdown("- **DiferenÃ§a 2-5%**: Leve overfitting âš ï¸")
            st.markdown("- **DiferenÃ§a > 5%**: Overfitting significativo âŒ")
            
            # Calcula diferenÃ§as
            acc_diff = train_metrics['accuracy'] - results['accuracy']
            f1_diff = train_metrics['f1_score'] - results['f1_score']
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                delta_acc = f"{acc_diff:.4f}"
                delta_color = "normal" if abs(acc_diff) < 0.02 else "inverse" if acc_diff > 0.05 else "off"
                st.metric("AcurÃ¡cia (Teste)", f"{results['accuracy']:.4f}", 
                         delta=f"Treino: {train_metrics['accuracy']:.4f} ({delta_acc})",
                         delta_color=delta_color)
            with col2:
                delta_prec = train_metrics['precision'] - results['precision']
                st.metric("PrecisÃ£o (Teste)", f"{results['precision']:.4f}",
                         delta=f"Treino: {train_metrics['precision']:.4f} ({delta_prec:+.4f})")
            with col3:
                delta_rec = train_metrics['recall'] - results['recall']
                st.metric("Recall (Teste)", f"{results['recall']:.4f}",
                         delta=f"Treino: {train_metrics['recall']:.4f} ({delta_rec:+.4f})")
            with col4:
                delta_color_f1 = "normal" if abs(f1_diff) < 0.02 else "inverse" if f1_diff > 0.05 else "off"
                st.metric("F1-Score (Teste)", f"{results['f1_score']:.4f}",
                         delta=f"Treino: {train_metrics['f1_score']:.4f} ({f1_diff:+.4f})",
                         delta_color=delta_color_f1)
            
            # Aviso sobre overfitting
            if abs(acc_diff) > 0.05:
                st.error(f"âŒ **Overfitting Detectado!**")
                st.warning(f"""
                **DiferenÃ§a de acurÃ¡cia entre treino e teste: {abs(acc_diff)*100:.2f}%**
                
                O modelo estÃ¡ performando muito melhor no treino do que no teste, indicando overfitting.
                
                **SoluÃ§Ãµes:**
                - Reduza ainda mais a complexidade do modelo (menos Ã¡rvores, menor profundidade)
                - Aumente `min_samples_split` e `min_samples_leaf` (Random Forest)
                - Aumente regularizaÃ§Ã£o (subsample, colsample_bytree para XGBoost)
                - Reduza `learning_rate` e aumente `n_estimators` (XGBoost)
                """)
            elif abs(acc_diff) > 0.02:
                st.warning(f"âš ï¸ **Leve Overfitting Detectado**")
                st.info(f"DiferenÃ§a de acurÃ¡cia: {abs(acc_diff)*100:.2f}%. Considere reduzir um pouco a complexidade do modelo.")
            else:
                st.success("âœ… **Modelo generaliza bem!** DiferenÃ§a entre treino e teste Ã© pequena.")
        else:
            # Se nÃ£o houver mÃ©tricas de treino, mostra apenas teste
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("AcurÃ¡cia", f"{results['accuracy']:.4f}", delta=None)
            with col2:
                st.metric("PrecisÃ£o", f"{results['precision']:.4f}", delta=None)
            with col3:
                st.metric("Recall", f"{results['recall']:.4f}", delta=None)
            with col4:
                st.metric("F1-Score", f"{results['f1_score']:.4f}", delta=None)
        
        # ExplicaÃ§Ã£o sobre 93%+ de acurÃ¡cia
        if results['accuracy'] >= 0.93 and results['accuracy'] < 0.99:
            st.info("ğŸ’¡ **Sobre acurÃ¡cia de 93%+:**")
            st.markdown("""
            Uma acurÃ¡cia de 93%+ **nÃ£o necessariamente indica overfitting**. Depende da diferenÃ§a entre treino e teste:
            
            - **Se a diferenÃ§a for pequena (< 2%)**: O modelo estÃ¡ generalizando bem! âœ…
            - **Se a diferenÃ§a for grande (> 5%)**: HÃ¡ overfitting, mesmo com 93% no teste âŒ
            
            Para o dataset N-BaIoT (detecÃ§Ã£o de botnet), 93-97% de acurÃ¡cia Ã© **razoÃ¡vel e esperado** 
            quando o modelo estÃ¡ bem ajustado, pois os padrÃµes de trÃ¡fego normal vs ataque sÃ£o relativamente distintos.
            """)
        
        # Aviso sobre mÃ©tricas muito altas (independente de overfitting)
        if results['accuracy'] >= 0.99:
            st.warning("âš ï¸ **AtenÃ§Ã£o: MÃ©tricas muito altas (â‰¥99%)**")
            st.markdown("""
            MÃ©tricas perfeitas ou quase perfeitas podem indicar:
            
            **1. Data Leakage (Vazamento de Dados)**
            - Alguma feature pode conter informaÃ§Ã£o direta sobre a classe target
            - Verifique se hÃ¡ colunas derivadas da target nas features
            
            **2. Problema Muito Simples**
            - O dataset pode ser trivialmente separÃ¡vel
            - Verifique a distribuiÃ§Ã£o das classes e a complexidade do problema
            
            **3. Overfitting Extremo**
            - O modelo pode estar memorizando os dados de treino
            - Tente reduzir a complexidade do modelo (menos Ã¡rvores, menor profundidade)
            
            **4. Dataset Muito Pequeno ou Desbalanceado**
            - Poucos dados podem levar a resultados enganosos
            - Verifique o tamanho do dataset e a distribuiÃ§Ã£o das classes
            """)
            
            # DiagnÃ³sticos adicionais
            with st.expander("ğŸ” Ver DiagnÃ³sticos Detalhados", expanded=False):
                if st.session_state.X_train is not None and st.session_state.y_train is not None:
                    X_train = st.session_state.X_train
                    y_train = st.session_state.y_train
                    X_test = st.session_state.X_test
                    y_test = st.session_state.y_test
                    
                    st.markdown("### ğŸ“Š InformaÃ§Ãµes do Dataset")
                    col_d1, col_d2, col_d3, col_d4 = st.columns(4)
                    with col_d1:
                        st.metric("Treino (amostras)", f"{len(X_train):,}")
                    with col_d2:
                        st.metric("Teste (amostras)", f"{len(X_test):,}")
                    with col_d3:
                        st.metric("Features", len(X_train.columns))
                    with col_d4:
                        n_classes = len(np.unique(y_train))
                        st.metric("Classes", n_classes)
                    
                    st.markdown("### ğŸ“ˆ DistribuiÃ§Ã£o das Classes")
                    col_dist1, col_dist2 = st.columns(2)
                    
                    with col_dist1:
                        st.markdown("**Treino:**")
                        train_dist = pd.Series(y_train).value_counts().sort_index()
                        st.dataframe(train_dist.to_frame(name="Amostras"), width='stretch')
                        
                    with col_dist2:
                        st.markdown("**Teste:**")
                        test_dist = pd.Series(y_test).value_counts().sort_index()
                        st.dataframe(test_dist.to_frame(name="Amostras"), width='stretch')
                    
                    # Verifica se hÃ¡ classes com muito poucas amostras
                    train_min = train_dist.min()
                    test_min = test_dist.min()
                    if train_min < 5 or test_min < 5:
                        st.warning(f"âš ï¸ Algumas classes tÃªm muito poucas amostras (mÃ­nimo: treino={train_min}, teste={test_min}). Isso pode causar mÃ©tricas enganosas.")
                    
                    # Verifica correlaÃ§Ã£o entre features e target (possÃ­vel data leakage)
                    st.markdown("### ğŸ” VerificaÃ§Ã£o de Data Leakage")
                    try:
                        # Calcula correlaÃ§Ã£o entre features numÃ©ricas e target
                        if len(X_train.columns) > 0:
                            # Cria um DataFrame temporÃ¡rio para anÃ¡lise
                            temp_df = X_train.copy()
                            temp_df['target'] = y_train
                            
                            # Calcula correlaÃ§Ãµes
                            correlations = temp_df.corr()['target'].drop('target').abs().sort_values(ascending=False)
                            
                            high_corr = correlations[correlations > 0.9]
                            if len(high_corr) > 0:
                                st.error(f"ğŸš¨ **PossÃ­vel Data Leakage Detectado!**")
                                st.warning(f"Encontradas {len(high_corr)} feature(s) com correlaÃ§Ã£o > 0.9 com a target:")
                                st.dataframe(high_corr.to_frame(name="CorrelaÃ§Ã£o"), width='stretch')
                                st.info("ğŸ’¡ Features com correlaÃ§Ã£o muito alta podem estar vazando informaÃ§Ã£o sobre a classe target. Considere removÃª-las.")
                            else:
                                st.success("âœ… Nenhuma feature com correlaÃ§Ã£o suspeitamente alta (>0.9) encontrada.")
                            
                            # Mostra top 10 correlaÃ§Ãµes
                            st.markdown("**Top 10 Features com Maior CorrelaÃ§Ã£o (absoluta) com Target:**")
                            top_corr = correlations.head(10)
                            st.dataframe(top_corr.to_frame(name="CorrelaÃ§Ã£o"), width='stretch')
                    except Exception as e:
                        st.info(f"â„¹ï¸ NÃ£o foi possÃ­vel calcular correlaÃ§Ãµes: {str(e)}")
                    
                    # Verifica se o problema Ã© muito simples (classes muito separadas)
                    st.markdown("### ğŸ¯ AnÃ¡lise de Separabilidade")
                    if n_classes == 2:
                        st.info("â„¹ï¸ Problema binÃ¡rio (2 classes). Verifique se as classes sÃ£o facilmente separÃ¡veis.")
                    elif n_classes < 5:
                        st.info(f"â„¹ï¸ Problema com {n_classes} classes. Poucas classes podem facilitar a classificaÃ§Ã£o.")
                    else:
                        st.info(f"â„¹ï¸ Problema multiclasse com {n_classes} classes.")
                    
                    # Verifica balanceamento
                    train_balance = train_dist.min() / train_dist.max()
                    if train_balance < 0.1:
                        st.warning("âš ï¸ Dataset muito desbalanceado! A classe menor tem menos de 10% das amostras da classe maior.")
                        st.info("ğŸ’¡ Considere usar tÃ©cnicas de balanceamento (SMOTE, undersampling, etc.) ou mÃ©tricas adequadas para dados desbalanceados.")
        
        # Matriz de confusÃ£o
        st.subheader("3. Matriz de ConfusÃ£o")
        
        cm = results['confusion_matrix']
        
        # Cria visualizaÃ§Ã£o da matriz de confusÃ£o
        fig_cm = go.Figure(data=go.Heatmap(
            z=cm,
            colorscale='Blues',
            text=cm,
            texttemplate='%{text}',
            textfont={"size": 10},
            hoverongaps=False
        ))
        
        fig_cm.update_layout(
            title="Matriz de ConfusÃ£o",
            xaxis_title="PrediÃ§Ã£o",
            yaxis_title="Valor Real",
            width=700,
            height=600
        )
        
        st.plotly_chart(fig_cm, width='stretch')
        
        # RelatÃ³rio de classificaÃ§Ã£o
        st.subheader("4. RelatÃ³rio de ClassificaÃ§Ã£o Detalhado")
        
        report_df = pd.DataFrame(results['classification_report']).transpose()
        # Converte valores numÃ©ricos para float64 explÃ­cito
        for col in report_df.select_dtypes(include=[np.number]).columns:
            report_df[col] = report_df[col].astype('float64')
        st.dataframe(report_df, width='stretch')
        
        # Feature Importance
        st.subheader("5. ImportÃ¢ncia das Features (Top 20)")
        
        if st.session_state.model is not None and st.session_state.X_train is not None:
            feature_names = st.session_state.X_train.columns.tolist()
            importance_df = get_feature_importance(st.session_state.model, feature_names, top_n=20)
            
            if importance_df is not None:
                fig_importance = px.bar(
                    importance_df,
                    x='Importance',
                    y='Feature',
                    orientation='h',
                    title="Top 20 Features Mais Importantes",
                    labels={'Importance': 'ImportÃ¢ncia', 'Feature': 'Feature'}
                )
                fig_importance.update_layout(yaxis={'categoryorder': 'total ascending'})
                st.plotly_chart(fig_importance, width='stretch')
                
                # Garante tipos compatÃ­veis
                importance_df['Importance'] = importance_df['Importance'].astype('float64')
                st.dataframe(importance_df, width='stretch')
            else:
                st.info("â„¹ï¸ Este algoritmo nÃ£o fornece feature importance direta.")
        
        # DistribuiÃ§Ã£o de prediÃ§Ãµes
        st.subheader("6. DistribuiÃ§Ã£o de PrediÃ§Ãµes")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # DistribuiÃ§Ã£o das classes reais
            y_test = results['y_test']
            unique, counts = np.unique(y_test, return_counts=True)
            fig_real = px.pie(
                values=counts,
                names=[f"Classe {u}" for u in unique],
                title="DistribuiÃ§Ã£o das Classes Reais (Teste)"
            )
            st.plotly_chart(fig_real, width='stretch')
        
        with col2:
            # DistribuiÃ§Ã£o das prediÃ§Ãµes
            y_pred = results['y_pred']
            unique_pred, counts_pred = np.unique(y_pred, return_counts=True)
            fig_pred = px.pie(
                values=counts_pred,
                names=[f"Classe {u}" for u in unique_pred],
                title="DistribuiÃ§Ã£o das PrediÃ§Ãµes"
            )
            st.plotly_chart(fig_pred, width='stretch')
        
        # ComparaÃ§Ã£o Real vs Predito
        st.subheader("6. ComparaÃ§Ã£o: Real vs Predito")
        
        comparison_df = pd.DataFrame({
            'Real': y_test,
            'Predito': y_pred
        })
        
        # Contagem de acertos e erros
        comparison_df['Acerto'] = comparison_df['Real'] == comparison_df['Predito']
        
        accuracy_by_class = comparison_df.groupby('Real').agg({
            'Acerto': 'mean'
        }).reset_index()
        accuracy_by_class.columns = ['Classe', 'Taxa de Acerto']
        
        fig_accuracy = px.bar(
            accuracy_by_class,
            x='Classe',
            y='Taxa de Acerto',
            title="Taxa de Acerto por Classe",
            labels={'Classe': 'Classe', 'Taxa de Acerto': 'Taxa de Acerto'}
        )
        st.plotly_chart(fig_accuracy, width='stretch')

# RodapÃ©
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: #666; padding: 1rem;'>"
    "Projeto de Mestrado - Aprendizado de MÃ¡quina | "
    "Dataset: N-BaIoT | Algoritmo: Random Forest"
    "</div>",
    unsafe_allow_html=True
)

